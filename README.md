The Problem


Given the attached text file as an argument, your program will read the file, and output the 20 most frequently used words in the file in order, along with their frequency. The output should be the same to that of the following bash program:

#!/usr/bin/env bash
cat $1 | tr -cs 'a-zA-Z' '[\n*]' | grep -v "^$" | tr '[:upper:]' '[:lower:]'| sort | uniq -c | sort -nr | head -20



Build Linux: "./mvnw clean package"

Build Windows: ".\mvnw.cmd clean package"

Run: "java -jar FrequentlyWords.jar <path to file>"

Java version: 17

Описание решения:


Решение основано на ограничении, что не разрешено использовать такие классы как Map и String.
Для решения я реализовал структуру "Префиксное дерево" (класс Node),
в котором дополнительно в терминальной ноде создал поле "count" для подсчета количества слов.
Посимвольно читается входной файл и формируется дерево.
Для вывода 20-ти часто встречающихся слов я реализовал структуру данных "Куча"(также известная как "Приоритетная очередь" и "Пирамида").

После построения дерева обходим его в глубину попутно собирая слова и в терминальных нодах сбрасываем их в кучу.

В конце проходим по куче до конца, но не более 20-ти раз и выводим элементы.

Временная сложность:

Посимвольная обработка файла и построение префиксного дерева O(n), где n-это количество символов

Обход в глубину O(n), где n-это количество узлов дерева

Вставка и удаление из кучи O(log n), где n-это количество элементов в куче, то есть уникальных слов в тексте

Таким образом общая временная сложность всего решения равна O(n), где n-это количество символов

Пространственная сложность:

Префиксное дерево стоит O(n), где n-это суммарная длина уникальных слов в тексте

Куча стоит O(m), где m-это количество уникальных слов в тексте

Таким образом общая пространственная сложность всего решения равна:
O(m) + O(n), где n-это суммарная длина уникальных слов в тексте, m-это количество уникальных слов в тексте

